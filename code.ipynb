{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8520467,"sourceType":"datasetVersion","datasetId":5087352}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TrainingImagePath='/kaggle/input/face-images1/Final Training Images'\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nimport matplotlib.pyplot as plt\n\ntrain_datagen = ImageDataGenerator(\n    shear_range=0.1,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    rescale=1.0/255.0\n)\n \ntest_datagen = ImageDataGenerator(rescale=1.0/255.0)\n\ntraining_set = train_datagen.flow_from_directory(\n        TrainingImagePath,\n        target_size=(64, 64),\n        batch_size=32,\n        class_mode='categorical')\n \ntest_set = test_datagen.flow_from_directory(\n        TrainingImagePath,\n        target_size=(64, 64),\n        batch_size=32,\n        class_mode='categorical')\n\ntest_set.class_indices","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:44:07.631375Z","iopub.execute_input":"2024-05-26T10:44:07.631806Z","iopub.status.idle":"2024-05-26T10:44:07.686933Z","shell.execute_reply.started":"2024-05-26T10:44:07.631773Z","shell.execute_reply":"2024-05-26T10:44:07.685811Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Found 244 images belonging to 16 classes.\nFound 244 images belonging to 16 classes.\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'face1': 0,\n 'face10': 1,\n 'face11': 2,\n 'face12': 3,\n 'face13': 4,\n 'face14': 5,\n 'face15': 6,\n 'face16': 7,\n 'face2': 8,\n 'face3': 9,\n 'face4': 10,\n 'face5': 11,\n 'face6': 12,\n 'face7': 13,\n 'face8': 14,\n 'face9': 15}"},"metadata":{}}]},{"cell_type":"code","source":"\nTrainClasses=training_set.class_indices\n\nResultMap={}\nfor faceValue,faceName in zip(TrainClasses.values(),TrainClasses.keys()):\n    ResultMap[faceValue]=faceName\n\nimport pickle\nwith open(\"ResultsMap.pkl\", 'wb') as fileWriteStream:\n    pickle.dump(ResultMap, fileWriteStream)\n \nprint(\"Mapping of Face and its ID\",ResultMap)\n\nOutputNeurons=len(ResultMap)\nprint('\\n The Number of output neurons: ', OutputNeurons)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:36:16.387878Z","iopub.execute_input":"2024-05-26T09:36:16.388302Z","iopub.status.idle":"2024-05-26T09:36:16.397558Z","shell.execute_reply.started":"2024-05-26T09:36:16.388271Z","shell.execute_reply":"2024-05-26T09:36:16.396262Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Mapping of Face and its ID {0: 'face1', 1: 'face10', 2: 'face11', 3: 'face12', 4: 'face13', 5: 'face14', 6: 'face15', 7: 'face16', 8: 'face2', 9: 'face3', 10: 'face4', 11: 'face5', 12: 'face6', 13: 'face7', 14: 'face8', 15: 'face9'}\n\n The Number of output neurons:  16\n","output_type":"stream"}]},{"cell_type":"code","source":"\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPool2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Input \n\nclassifier= Sequential()\n\nclassifier.add(Input(shape=(64, 64, 3)))\n\nclassifier.add(Convolution2D(32, kernel_size=(5, 5), strides=(1, 1), input_shape=(64,64,3), activation='relu'))\n\nclassifier.add(MaxPool2D(pool_size=(2,2)))\n\nclassifier.add(Convolution2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n \nclassifier.add(MaxPool2D(pool_size=(2,2)))\n\nclassifier.add(Flatten())\n\nclassifier.add(Dense(64, activation='relu'))\n \nclassifier.add(Dense(OutputNeurons, activation='softmax'))\n\nclassifier.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=[\"accuracy\"])\n\nimport time\nStartTime=time.time()\n\nclassifier.fit(\n                    training_set,\n                    steps_per_epoch=30,\n                    epochs=10,\n                    validation_data=test_set,\n                    validation_steps=10)\n \nEndTime=time.time()\nprint(\"###### Total Time Taken: \", round((EndTime-StartTime)/60), 'Minutes ######')","metadata":{"execution":{"iopub.status.busy":"2024-05-26T10:44:19.386284Z","iopub.execute_input":"2024-05-26T10:44:19.386926Z","iopub.status.idle":"2024-05-26T10:45:06.051560Z","shell.execute_reply.started":"2024-05-26T10:44:19.386894Z","shell.execute_reply":"2024-05-26T10:45:06.050324Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.0615 - loss: 2.9119 - val_accuracy: 0.1270 - val_loss: 2.7635\nEpoch 2/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 0.0966 - loss: 2.7606 - val_accuracy: 0.0697 - val_loss: 2.7165\nEpoch 3/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 0.0999 - loss: 2.7064 - val_accuracy: 0.2992 - val_loss: 2.5892\nEpoch 4/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.2684 - loss: 2.5616 - val_accuracy: 0.3197 - val_loss: 2.3509\nEpoch 5/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.3342 - loss: 2.2847 - val_accuracy: 0.3852 - val_loss: 1.9416\nEpoch 6/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.5227 - loss: 1.8525 - val_accuracy: 0.6352 - val_loss: 1.3681\nEpoch 7/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.6297 - loss: 1.4641 - val_accuracy: 0.8402 - val_loss: 0.9837\nEpoch 8/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 0.7528 - loss: 1.0710 - val_accuracy: 0.9180 - val_loss: 0.5877\nEpoch 9/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.8731 - loss: 0.6129 - val_accuracy: 0.9303 - val_loss: 0.3637\nEpoch 10/10\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.9062 - loss: 0.4008 - val_accuracy: 0.9918 - val_loss: 0.1674\n###### Total Time Taken:  1 Minutes ######\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom keras.preprocessing import image\n \nImagePath='/kaggle/input/face-images1/Final Training Images/face13/image_0288_Face_1.jpg'\ntest_image=image.load_img(ImagePath,target_size=(64, 64))\ntest_image=image.img_to_array(test_image)\n \ntest_image=np.expand_dims(test_image,axis=0)\n \nresult=classifier.predict(test_image,verbose=0)\n \nprint('####'*10)\nprint('Prediction is: ',ResultMap[np.argmax(result)])","metadata":{"execution":{"iopub.status.busy":"2024-05-26T09:43:53.931609Z","iopub.execute_input":"2024-05-26T09:43:53.932023Z","iopub.status.idle":"2024-05-26T09:43:54.109701Z","shell.execute_reply.started":"2024-05-26T09:43:53.931994Z","shell.execute_reply":"2024-05-26T09:43:54.108187Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"########################################\nPrediction is:  face13\n","output_type":"stream"}]}]}